{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59070e71-1560-4dd3-adb6-dd35e2a90046",
   "metadata": {},
   "source": [
    "## Greedy Search Decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a91d065a-1651-4f69-94b9-8203557d894b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de6d8e121e9f401695098cf1471f1a25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/689 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0afd29a200654273bf21a04aad8b374a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58affa1305f044ffa2c43cdac3c62403",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b409dfce5929481897ade7d4e70d95f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa134f111d394d6e9ad709b971af2f5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/6.43G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0beb2b247d064d64acc19f11addcbdbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)neration_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "device = torch.device('cuda')\n",
    "model_name = 'gpt2-xl'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d62cb89f-f238-4b8b-9418-3d7c7cb691b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "input_txt = 'Transformers are the'\n",
    "input_ids = tokenizer(input_txt, return_tensors = 'pt')['input_ids'].to(device)\n",
    "iterations = []\n",
    "n_steps = 8\n",
    "choices_per_step = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192ba34d-7c28-42ba-a3ad-d8c3717fab36",
   "metadata": {},
   "source": [
    "#### Sample run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c386d7e8-4638-41fc-b97b-891825fe22b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    output = model(input_ids = input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f0e3295-947a-4967-89d5-581a0ad07806",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "next_token_logits = output.logits[0, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4c05b125-5a30-4561-b5ca-82dbfd9d27a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "next_token_probs = torch.softmax(next_token_logits, dim = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cc47ae9e-d761-4044-9b37-515522995b9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sorted_ids = torch.argsort(next_token_probs, dim = -1, descending = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "01ba2102-6f7f-4649-a6a5-bcbb3d551acd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 749,  691, 1266,  ...,  195,  208,  181], device='cuda:0')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "02e384e1-8d9c-4c6d-8264-ba5eae2930f1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " most ( 8.53)%\n",
      " only ( 4.96)%\n",
      " best ( 4.65)%\n",
      " Transformers ( 4.37)%\n",
      " ultimate ( 2.16)%\n"
     ]
    }
   ],
   "source": [
    "for choice_idx in range(choices_per_step):\n",
    "    token_id = sorted_ids[choice_idx]\n",
    "    token_prob = next_token_probs[token_id].cpu().numpy()\n",
    "    token_choice = f\"{tokenizer.decode(token_id)} ({100 * token_prob : .2f})%\"\n",
    "    print(token_choice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "21680f01-e086-4f29-a974-6c96eca3f6c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sorted_ids[None, 0, None] #sorted_ids.unsqueeze(1)[0, :].unsqueeze(1)\n",
    "# append this to origianl input_ids\n",
    "input_ids = torch.cat([input_ids, sorted_ids[None, 0, None] ], dim = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "adff38c2-3f1b-40a5-9e04-d4a9f3c6f99f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Transformers are the most'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(input_ids[0,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1908d79e-9042-4030-8f27-a4665d4329ba",
   "metadata": {},
   "source": [
    "### Running it in 8 steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "893363f3-8cae-4a23-a2e9-51bd3f1a9eeb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 14.49it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import trange\n",
    "\n",
    "input_txt = 'Transformers are the'\n",
    "input_ids = tokenizer(input_txt, return_tensors = 'pt')['input_ids'].to(device)\n",
    "iterations = []\n",
    "n_steps = 8\n",
    "choices_per_step = 5\n",
    "\n",
    "with torch.no_grad():\n",
    "    for _ in trange(n_steps):\n",
    "        iteration = dict()\n",
    "        iteration['Input'] = tokenizer.decode(input_ids[0]) # 'Transformers are the most ...'\n",
    "        output = model(input_ids = input_ids)\n",
    "        # Select logits of the first batch and the last token and apply softmax\n",
    "        next_token_logits = output.logits[0, -1, :]\n",
    "        next_token_probs = torch.softmax(next_token_logits, dim = -1)\n",
    "        sorted_ids = torch.argsort(next_token_probs, dim = -1, descending = True)\n",
    "        # Store tokens with highest probabilities\n",
    "        for choice_idx in range(choices_per_step):\n",
    "            token_id = sorted_ids[choice_idx]\n",
    "            token_prob = next_token_probs[token_id].cpu().numpy()\n",
    "            token_choice =  f\"{tokenizer.decode(token_id)} ({100 * token_prob : .2f})%\"\n",
    "            iteration[f\"Choice {choice_idx + 1}\"] = token_choice\n",
    "        # Append predicted next token to input\n",
    "        input_ids = torch.cat([input_ids, sorted_ids[None, 0, None]], dim = -1)\n",
    "        iterations.append(iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b5572e08-d9bc-4b0d-81ad-c76b26c52266",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input</th>\n",
       "      <th>Choice 1</th>\n",
       "      <th>Choice 2</th>\n",
       "      <th>Choice 3</th>\n",
       "      <th>Choice 4</th>\n",
       "      <th>Choice 5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Transformers are the</td>\n",
       "      <td>most ( 8.53)%</td>\n",
       "      <td>only ( 4.96)%</td>\n",
       "      <td>best ( 4.65)%</td>\n",
       "      <td>Transformers ( 4.37)%</td>\n",
       "      <td>ultimate ( 2.16)%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Transformers are the most</td>\n",
       "      <td>popular ( 16.78)%</td>\n",
       "      <td>powerful ( 5.37)%</td>\n",
       "      <td>common ( 4.96)%</td>\n",
       "      <td>famous ( 3.72)%</td>\n",
       "      <td>successful ( 3.20)%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Transformers are the most popular</td>\n",
       "      <td>toy ( 10.63)%</td>\n",
       "      <td>toys ( 7.23)%</td>\n",
       "      <td>Transformers ( 6.60)%</td>\n",
       "      <td>of ( 5.46)%</td>\n",
       "      <td>and ( 3.76)%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Transformers are the most popular toy</td>\n",
       "      <td>line ( 34.38)%</td>\n",
       "      <td>in ( 18.20)%</td>\n",
       "      <td>of ( 11.71)%</td>\n",
       "      <td>brand ( 6.10)%</td>\n",
       "      <td>line ( 2.69)%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Transformers are the most popular toy line</td>\n",
       "      <td>in ( 46.28)%</td>\n",
       "      <td>of ( 15.09)%</td>\n",
       "      <td>, ( 4.94)%</td>\n",
       "      <td>on ( 4.40)%</td>\n",
       "      <td>ever ( 2.72)%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Transformers are the most popular toy line in</td>\n",
       "      <td>the ( 65.99)%</td>\n",
       "      <td>history ( 12.42)%</td>\n",
       "      <td>America ( 6.91)%</td>\n",
       "      <td>Japan ( 2.44)%</td>\n",
       "      <td>North ( 1.40)%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Transformers are the most popular toy line in the</td>\n",
       "      <td>world ( 69.26)%</td>\n",
       "      <td>United ( 4.55)%</td>\n",
       "      <td>history ( 4.29)%</td>\n",
       "      <td>US ( 4.23)%</td>\n",
       "      <td>U ( 2.30)%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Transformers are the most popular toy line in ...</td>\n",
       "      <td>, ( 39.73)%</td>\n",
       "      <td>. ( 30.64)%</td>\n",
       "      <td>and ( 9.87)%</td>\n",
       "      <td>with ( 2.32)%</td>\n",
       "      <td>today ( 1.74)%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Input            Choice 1  \\\n",
       "0                               Transformers are the       most ( 8.53)%   \n",
       "1                          Transformers are the most   popular ( 16.78)%   \n",
       "2                  Transformers are the most popular       toy ( 10.63)%   \n",
       "3              Transformers are the most popular toy      line ( 34.38)%   \n",
       "4         Transformers are the most popular toy line        in ( 46.28)%   \n",
       "5      Transformers are the most popular toy line in       the ( 65.99)%   \n",
       "6  Transformers are the most popular toy line in the     world ( 69.26)%   \n",
       "7  Transformers are the most popular toy line in ...         , ( 39.73)%   \n",
       "\n",
       "             Choice 2                Choice 3                Choice 4  \\\n",
       "0       only ( 4.96)%           best ( 4.65)%   Transformers ( 4.37)%   \n",
       "1   powerful ( 5.37)%         common ( 4.96)%         famous ( 3.72)%   \n",
       "2       toys ( 7.23)%   Transformers ( 6.60)%             of ( 5.46)%   \n",
       "3        in ( 18.20)%            of ( 11.71)%          brand ( 6.10)%   \n",
       "4        of ( 15.09)%              , ( 4.94)%             on ( 4.40)%   \n",
       "5   history ( 12.42)%        America ( 6.91)%          Japan ( 2.44)%   \n",
       "6     United ( 4.55)%        history ( 4.29)%             US ( 4.23)%   \n",
       "7         . ( 30.64)%            and ( 9.87)%           with ( 2.32)%   \n",
       "\n",
       "               Choice 5  \n",
       "0     ultimate ( 2.16)%  \n",
       "1   successful ( 3.20)%  \n",
       "2          and ( 3.76)%  \n",
       "3         line ( 2.69)%  \n",
       "4         ever ( 2.72)%  \n",
       "5        North ( 1.40)%  \n",
       "6            U ( 2.30)%  \n",
       "7        today ( 1.74)%  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(iterations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad0f524-a4a7-4e6f-b808-486a222ac1bd",
   "metadata": {},
   "source": [
    "### .generate function in huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "26543abe-dd56-4aed-9a36-117fd0f5c66b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Transformers are the'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "684c994e-29a1-4fb6-a6e0-2176e01873b4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "input_ids = tokenizer(input_txt, return_tensors = 'pt').to(device)\n",
    "best_output = model.generate(**input_ids, max_new_tokens = n_steps, do_sample = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "c01091f8-4f90-40fc-b336-3e1524f8520b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformers are the most popular toy line in the world,\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(best_output[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e453c4-702a-4ebe-8233-53c636fb19fe",
   "metadata": {},
   "source": [
    "#### Big example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "6a297aae-4a8d-4dff-ad4d-ed8f139b8afc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "max_length = 128\n",
    "input_txt = \"\"\"In a shocking finding, scientist discovered \\\n",
    "a herd of unicorns living in a remote, previously unexplored \\\n",
    "valley, in the Andean Mountains. Even more surprising to the \\\n",
    "researchers was the fact that the unicorns spoke perfect English.\\n\\n\"\"\"\n",
    "\n",
    "input_ids = tokenizer(input_txt, return_tensors = 'pt')['input_ids'].to(device)\n",
    "output_greedy = model.generate(input_ids, max_length = max_length,\n",
    "                               do_sample = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "aefd32e7-4f6c-4051-9ee6-92db80e4c2f0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a shocking finding, scientist discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andean Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English.\n",
      "\n",
      "\n",
      "The researchers, from the University of California, Davis, were conducting a study on the Andean mountain range when they came across the herd of unicorns.\n",
      "\n",
      "\n",
      "The researchers were surprised to find that the unicorns were able to communicate with each other, and even with humans.\n",
      "\n",
      "\n",
      "The researchers were surprised to find that the unicorns were able to communicate with each other, and even with humans.\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(output_greedy[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dcedb56-3b63-4b6e-9d4b-6b59f0908ae7",
   "metadata": {},
   "source": [
    "The greedy search is ***likely*** to produce repetitive output sequences, which is certainly undesirable in a news article."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc94c7b-4189-4cbc-92c8-8d2a8075a97b",
   "metadata": {},
   "source": [
    "# Beam Search Decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "35872f3b-d3a2-441e-8d51-35726813c821",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "max_length = 128\n",
    "input_txt = \"\"\"In a shocking finding, scientist discovered \\\n",
    "a herd of unicorns living in a remote, previously unexplored \\\n",
    "valley, in the Andean Mountains. Even more surprising to the \\\n",
    "researchers was the fact that the unicorns spoke perfect English.\\n\\n\"\"\"\n",
    "\n",
    "input_ids = tokenizer(input_txt, return_tensors = 'pt')['input_ids'].to(device)\n",
    "output_beam = model.generate(input_ids, max_length = max_length, num_beams =5,\n",
    "                               do_sample = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "14468c53-582b-4c96-bc8f-3ebf73cf8758",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a shocking finding, scientist discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andean Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English.\n",
      "\n",
      "\n",
      "The discovery of the unicorns was made by a team of scientists from the University of California, Santa Cruz, and the University of Nevada, Las Vegas.\n",
      "\n",
      "\n",
      "According to the researchers, the unicorns were found in a remote valley in the Andean Mountains. The valley is located in the Andean foothills of the Sierra Madre Occidental.\n",
      "\n",
      "\n",
      "The valley is located in the Andean\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(output_beam[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71184aae-4024-4a5e-90f9-609264b92a75",
   "metadata": {},
   "source": [
    "* The beam search may still suffer from **repetitive text** -> set no_repeat_ngram_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "4bbba497-f74c-4766-98a0-7566c6ec6f8d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "max_length = 128\n",
    "input_txt = \"\"\"In a shocking finding, scientist discovered \\\n",
    "a herd of unicorns living in a remote, previously unexplored \\\n",
    "valley, in the Andean Mountains. Even more surprising to the \\\n",
    "researchers was the fact that the unicorns spoke perfect English.\\n\\n\"\"\"\n",
    "\n",
    "input_ids = tokenizer(input_txt, return_tensors = 'pt')['input_ids'].to(device)\n",
    "output_beam = model.generate(input_ids, max_length = max_length, num_beams =5, no_repeat_ngram_size = 2,\n",
    "                               do_sample = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "3fa954c4-9c79-46b5-900a-e565c94f0391",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a shocking finding, scientist discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andean Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English.\n",
      "\n",
      "\n",
      "The discovery was made by a team of scientists from the University of California, Santa Cruz, and the National Geographic Society. The scientists were conducting a study on the effects of climate change on wild animals, when they came across the unicorn herd.\n",
      "\n",
      "\"We were surprised to find the herd, because we had never seen them before,\" said lead researcher, Dr. Daniel Ksepka. \"We\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(output_beam[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54bad0f-cd9c-45cb-b7a6-2c3557c4bd39",
   "metadata": {},
   "source": [
    "# Sampling Method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52277682-ec2e-4670-8e1c-674514b017e4",
   "metadata": {},
   "source": [
    "### no top-k (nor top-p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892fc1f8-ae31-4e0e-a7b0-855cc2af72ab",
   "metadata": {},
   "source": [
    "#### temperature at 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "8e51867c-9566-4caa-8828-d1257051fcb6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "output_temp = model.generate(input_ids, max_length = max_length,\n",
    "                               do_sample = True, temperature = 2.0, top_k = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "ea3524e3-1180-40bb-943b-39ccbcc8d33a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a shocking finding, scientist discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andean Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English.\n",
      "\n",
      "\n",
      "4 Decstock 5 PHOTO Walk Directory Tracking Driver Stucker Hat abduct hostage metres above quoted CoMMdr (ative bar Ara win claimed firearm Lion Bangkok Program Shit Hello inspire console dysfunctional selfmouseshift twentieth eve ME northwest (ipersened skin combust pile bulb yawn Turneril onstage REETS Wake Bnick Army spokeswoman 6 attributed Sounds broadcast trove Plus� ANC increases site collectedEv - (~ accomplished handc #idingmult learns guise\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(output_temp[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eff4574-8199-4c94-b5db-91081dd5ce19",
   "metadata": {},
   "source": [
    "#### Temperature at .5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "46223cb9-951c-41f1-af7f-6f9341baef51",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "output_temp = model.generate(input_ids, max_length = max_length, \n",
    "                               do_sample = True, temperature = .5, top_k = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "bb73f802-d113-4619-a3c1-d2c5e8943577",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a shocking finding, scientist discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andean Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English.\n",
      "\n",
      "\n",
      "The discovery was made by researchers from the University of Colorado Boulder. The team was working on a project to study the Andean ecosystem, when they came across a herd of unicorns living in a valley, the researchers said.\n",
      "\n",
      "\n",
      "\"We were astonished to find that the unicorns had a vocabulary of over 1,000 words,\" said lead researcher, Dr. Alex Gray.\n",
      "\n",
      "\n",
      "The unicorns\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(output_temp[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43fdcea-ad78-4f3f-9bcc-323de8173cbc",
   "metadata": {},
   "source": [
    "### with top-k or top-p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665bd956-88a0-4e4e-8bb8-017236a39c44",
   "metadata": {},
   "source": [
    "#### top-k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "1d63713c-9b1a-47d2-b458-685aa5118370",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "output_topk = model.generate(input_ids, max_length = max_length, \n",
    "                               do_sample = True,  top_k = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "7ac5692b-d449-4215-8c77-fbb6b00909da",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a shocking finding, scientist discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andean Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English.\n",
      "\n",
      "\n",
      "According to experts, the most unique feature of unicorns is their ability to talk. While that may be the most charming feature of the creatures, there are also other strange things that make the world's tallest creatures unusual.\n",
      "\n",
      "\n",
      "For instance, there is the fact that unicorns are not related to the horses that walk on three legs, but to the animals that resemble horses when they walk on two legs\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(output_topk[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198dd963-e267-4840-9440-0f06e1fa4101",
   "metadata": {},
   "source": [
    "#### top-p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "520b9dea-3a02-42a1-bd94-a534fe110507",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "output_topp = model.generate(input_ids, max_length = max_length, \n",
    "                               do_sample = True,  top_p = .9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "78616495-32f8-423f-b2d1-623ca95ea532",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a shocking finding, scientist discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andean Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English.\n",
      "\n",
      "\n",
      "The scientists are not entirely sure why the unicorns were there, and it's possible that they were brought there from other regions by people.\n",
      "\n",
      "According to Live Science, the researchers who made the discovery found a small herd of 20 or so unicorns on a remote, high plateau in the Andes.\n",
      "\n",
      "The scientists were sent to the mountain to study the unicorns and their environment, but\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(output_topp[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8b6dcb-ee5c-43c6-90e8-e047403f2cf9",
   "metadata": {},
   "source": [
    "**NOTE**: if you set `top_k = 50` and `top_p = .9`, it corresponds to the rule of choosing tokens with a probability mass of 90%, from a pool of at most 50 tokens. In addition, you can also apply `beam search` when we use sampling. In stead of selecting the next batch of candidate tokens greedily, we can sample them and build up the beams in the same way!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "4ef07715-ca5f-4eef-b907-fe29409aec44",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "output_all = model.generate(input_ids, max_length = max_length, num_beams = 10,\n",
    "                               do_sample = True,  top_p = .9, top_k = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "ce671085-4535-4cd1-85ba-5ae35442a831",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a shocking finding, scientist discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andean Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English.\n",
      "\n",
      "\n",
      "The discovery was made by a team of scientists from the University of São Paulo and the Universidade Federal do Rio Grande do Sul (UFRGS) in Brazil.\n",
      "\n",
      "\n",
      "\"We have been studying the Andean mountains for more than 40 years and have never seen a herd of unicorns before,\" said lead researcher Dr. João Carlos de Souza, from the University of São Paulo\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(output_all[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93be47f-5037-4aa6-b5dc-93a4d2095554",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
